{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "557baf47",
   "metadata": {},
   "source": [
    "Web Scrapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603a4171",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "requesting means to request the server \n",
    "if o/p is 400 is accepted other than 400 is rejected\n",
    "web scrapping is the process to scrap / extract the information from other sources\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31165d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web Scrapping library for BeautifulSoup\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from  datetime import datetime\n",
    "# Target URL news channel link\n",
    "url = 'https://www.lokmat.com/'\n",
    "\n",
    "#send HTTP GET request response \n",
    "response= request.get(url)\n",
    "''' \n",
    "Note = response =200 then it is successful to get data from url\n",
    "'''\n",
    "# check if request is successful\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content,'html.parser')\n",
    "    # locate headlines  and output show real website heading\n",
    "\n",
    "    headlines_html = soup.find_all('h3') #adjust if needed change\n",
    "\n",
    "    # extract text from user/ tags\n",
    "    headlines = [h.get_text(strip=True)for h in headlines_html if h.get_text(string=True)]\n",
    "\n",
    "    # converting data into two or multidimentional array\n",
    "    df = pd.DataFrame({\n",
    "        'headline': headlines,\n",
    "        'source':url,\n",
    "        'scraped_time':datetime.now()\n",
    "    }) \n",
    "\n",
    "    print(df.head())\n",
    "\n",
    "    df.to_csv('aajtak_headlines.csv', index =False,encoding= 'utf-8-sig')\n",
    "    print('Saved to aajtak headlines.csv')\n",
    "else:\n",
    "    print('failed to retrieve msg .status code : ',response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420f9ff7",
   "metadata": {},
   "source": [
    "File handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630014b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "functions in File Handling: r : read\n",
    "rb : read binary\n",
    "w : write\n",
    "wb : write binary\n",
    "a : append\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f47ec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"demo.txt\",\"r\")\n",
    "print(file)\n",
    "with open(\"demo.txt\",\"r\")as file:\n",
    "    content = file.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9408cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "def save_model(model,path):\n",
    "    with open(path,'wb')as f:\n",
    "        pickle.dump(model,f)\n",
    "\n",
    "def load_model(path):\n",
    "    with open(path,'rb')as f:\n",
    "        return pickle.load(f,,,,,,,,,,,,,,)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
